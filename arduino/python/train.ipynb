{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a146b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from IPython.display import Image, display\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "# --- Constants from original notebook ---\n",
    "# File paths\n",
    "SAVED_MODEL_FILENAME = \"saved_model_0_1\"  # Modified for 2-digit version\n",
    "FLOAT_TFL_MODEL_FILENAME = \"float_model_0_1.tfl\"\n",
    "QUANTIZED_TFL_MODEL_FILENAME = \"quantized_model_0_1.tfl\"\n",
    "TFL_CC_MODEL_FILENAME = \"magic_wand_model_data_0_1.cc\"\n",
    "\n",
    "# Image properties\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_HEIGHT = 32\n",
    "NUM_CHANNELS = 3  # RGB, due to color encoding of time in rasterization\n",
    "\n",
    "# Fixed-point arithmetic (for rasterization)\n",
    "FIXED_POINT = 4096\n",
    "\n",
    "# Data ranges for rasterization\n",
    "X_RANGE = 0.6  # Max expected x-coordinate deviation from center\n",
    "Y_RANGE = 0.6  # Max expected y-coordinate deviation from center\n",
    "\n",
    "# --- New constants for this version ---\n",
    "TARGET_LABELS = [\"0\", \"1\"]\n",
    "NUM_CLASSES = len(TARGET_LABELS)\n",
    "\n",
    "# Ensure output directories for models exist\n",
    "Path(\"checkpoints\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"Target labels: {TARGET_LABELS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3396d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_strokes = []\n",
    "# Assuming your data is in a 'data' subdirectory relative to the notebook\n",
    "# If your JSON files are named like '0.json', '1.json', etc.\n",
    "# and these names directly correspond to the labels.\n",
    "# Modify glob pattern if your files are named differently.\n",
    "\n",
    "# Create dummy data if it doesn't exist for demonstration\n",
    "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for filename in glob.glob(\"data/*.json\"):\n",
    "    with open(filename, \"r\") as file:\n",
    "        file_contents = file.read()\n",
    "    try:\n",
    "        file_data = json.loads(file_contents)\n",
    "        for stroke_idx, stroke in enumerate(file_data[\"strokes\"]):\n",
    "            stroke[\"filename\"] = filename\n",
    "            # Ensure 'index' exists, if not, use enumeration\n",
    "            if \"index\" not in stroke:\n",
    "                stroke[\"index\"] = stroke_idx\n",
    "            all_strokes.append(stroke)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Warning: Could not decode JSON from {filename}\")\n",
    "    except KeyError:\n",
    "        print(f\"Warning: 'strokes' key not found in {filename}\")\n",
    "\n",
    "print(f\"Total strokes loaded: {len(all_strokes)}\")\n",
    "\n",
    "# Filter for target labels\n",
    "filtered_strokes = [\n",
    "    s for s in all_strokes if str(s.get(\"label\", \"\")).strip() in TARGET_LABELS\n",
    "]\n",
    "\n",
    "print(f\"Strokes after filtering for {TARGET_LABELS}: {len(filtered_strokes)}\")\n",
    "\n",
    "# Basic check for stroke points\n",
    "valid_strokes = []\n",
    "for stroke in filtered_strokes:\n",
    "    if \"strokePoints\" in stroke and len(stroke[\"strokePoints\"]) > 1:\n",
    "        valid_strokes.append(stroke)\n",
    "    else:\n",
    "        print(\n",
    "            f\"Warning: Stroke from {stroke['filename']} (label: {stroke['label']}) \"\n",
    "            \"has insufficient points and will be skipped.\"\n",
    "        )\n",
    "strokes = valid_strokes\n",
    "print(f\"Valid strokes for training/testing: {len(strokes)}\")\n",
    "\n",
    "if not strokes:\n",
    "    raise ValueError(\n",
    "        \"No valid strokes found for the target labels. \"\n",
    "        \"Please check your data directory and JSON structure.\"\n",
    "    )\n",
    "\n",
    "# Analyze stroke lengths (optional, but good for understanding)\n",
    "if strokes:\n",
    "    func = lambda x: len(x[\"strokePoints\"])\n",
    "    values = list(map(func, strokes))\n",
    "    print(\n",
    "        f\"Stroke lengths for filtered data: \"\n",
    "        f\"min {np.min(values)}, max {np.max(values)}, \"\n",
    "        f\"avg {np.average(values):.2f}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"No strokes to analyze.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e2c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stroke(stroke):\n",
    "    \"\"\"Plots a single stroke.\"\"\"\n",
    "    x_array = []\n",
    "    y_array = []\n",
    "    if \"strokePoints\" not in stroke or not stroke[\"strokePoints\"]:\n",
    "        print(f\"Stroke has no points: {stroke.get('label', 'N/A')}\")\n",
    "        return\n",
    "\n",
    "    for coords in stroke[\"strokePoints\"]:\n",
    "        x_array.append(coords[\"x\"])\n",
    "        y_array.append(coords[\"y\"])\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 4))  # Adjusted size\n",
    "    title = str(stroke.get(\"label\", \"Unknown Label\"))\n",
    "    if \"filename\" in stroke and \"index\" in stroke:\n",
    "        title += f\" (from {Path(stroke['filename']).name}, index {stroke['index']})\"\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    ax = fig.add_subplot(111)  # Simpler subplot\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    # Dynamically set limits or use fixed ones from original\n",
    "    ax.set_xlim(-X_RANGE, X_RANGE)\n",
    "    ax.set_ylim(-Y_RANGE, Y_RANGE)\n",
    "    ax.plot(x_array, y_array)\n",
    "    ax.invert_yaxis()  # Often intuitive for drawing\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot one example of each target label, if available\n",
    "if strokes:\n",
    "    plotted_labels = set()\n",
    "    for stroke_to_plot in np.random.permutation(strokes):\n",
    "        label = str(stroke_to_plot.get(\"label\", \"\")).strip()\n",
    "        if label in TARGET_LABELS and label not in plotted_labels:\n",
    "            print(f\"Plotting sample for label: {label}\")\n",
    "            plot_stroke(stroke_to_plot)\n",
    "            plotted_labels.add(label)\n",
    "        if len(plotted_labels) == NUM_CLASSES:\n",
    "            break\n",
    "    if len(plotted_labels) < NUM_CLASSES:\n",
    "        print(\"Warning: Could not find samples for all target labels to plot.\")\n",
    "else:\n",
    "    print(\"No strokes available to plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed-point arithmetic functions (from original notebook)\n",
    "def mul_fp(a, b):\n",
    "    return (a * b) // FIXED_POINT\n",
    "\n",
    "\n",
    "def div_fp(a, b):\n",
    "    if b == 0:\n",
    "        b = 1  # Avoid division by zero\n",
    "    return (a * FIXED_POINT) // b\n",
    "\n",
    "\n",
    "def float_to_fp(a):\n",
    "    return math.floor(a * FIXED_POINT)\n",
    "\n",
    "\n",
    "def norm_to_coord_fp(a, range_fp, half_size_fp):\n",
    "    a_fp = float_to_fp(a)\n",
    "    norm_fp = div_fp(a_fp, range_fp)\n",
    "    return mul_fp(norm_fp, half_size_fp) + half_size_fp\n",
    "\n",
    "\n",
    "def round_fp_to_int(a):\n",
    "    return math.floor((a + (FIXED_POINT // 2)) / FIXED_POINT)\n",
    "\n",
    "\n",
    "def gate(a, min_val, max_val):\n",
    "    if a < min_val:\n",
    "        return min_val\n",
    "    elif a > max_val:\n",
    "        return max_val\n",
    "    else:\n",
    "        return a\n",
    "\n",
    "\n",
    "def rasterize_stroke(stroke_points, x_range, y_range, width, height):\n",
    "    \"\"\"\n",
    "    Rasterizes stroke points into an image buffer with time encoded as color.\n",
    "    x_range: The expected maximum deviation of x-coordinates from the center (e.g., 0.5 means coords range from -0.5 to 0.5)\n",
    "    y_range: Similar for y-coordinates.\n",
    "    width: Output image width in pixels.\n",
    "    height: Output image height in pixels.\n",
    "    \"\"\"\n",
    "    if not stroke_points or len(stroke_points) < 2:\n",
    "        # Return a blank image if not enough points\n",
    "        return np.zeros((height, width, NUM_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "    buffer_byte_count = height * width * NUM_CHANNELS\n",
    "    buffer = bytearray(buffer_byte_count)  # Initialize with zeros (black)\n",
    "\n",
    "    width_fp = float_to_fp(width)  # Use float_to_fp for consistency\n",
    "    height_fp = float_to_fp(height)\n",
    "    half_width_fp = width_fp // 2\n",
    "    half_height_fp = height_fp // 2\n",
    "    x_range_fp = float_to_fp(x_range)\n",
    "    y_range_fp = float_to_fp(y_range)\n",
    "\n",
    "    # Ensure t_inc_fp is not zero\n",
    "    num_segments = len(stroke_points) - 1\n",
    "    if num_segments == 0:  # single point, can't draw lines\n",
    "        # Optionally draw a single point or return blank\n",
    "        return np.frombuffer(buffer, dtype=np.uint8).reshape(\n",
    "            height, width, NUM_CHANNELS\n",
    "        )\n",
    "\n",
    "    t_inc_fp = FIXED_POINT // num_segments if num_segments > 0 else FIXED_POINT\n",
    "\n",
    "    one_half_fp = FIXED_POINT // 2\n",
    "\n",
    "    for point_index in range(num_segments):\n",
    "        start_point = stroke_points[point_index]\n",
    "        end_point = stroke_points[point_index + 1]\n",
    "\n",
    "        # Normalize coordinates and scale to image dimensions using fixed point\n",
    "        # Y is often inverted in screen coordinates vs. array indexing.\n",
    "        # The original used -start_point[\"y\"], so we keep that.\n",
    "        start_x_fp = norm_to_coord_fp(start_point[\"x\"], x_range_fp, half_width_fp)\n",
    "        start_y_fp = norm_to_coord_fp(-start_point[\"y\"], y_range_fp, half_height_fp)\n",
    "        end_x_fp = norm_to_coord_fp(end_point[\"x\"], x_range_fp, half_width_fp)\n",
    "        end_y_fp = norm_to_coord_fp(-end_point[\"y\"], y_range_fp, half_height_fp)\n",
    "\n",
    "        delta_x_fp = end_x_fp - start_x_fp\n",
    "        delta_y_fp = end_y_fp - start_y_fp\n",
    "\n",
    "        # Determine color based on progress through the stroke\n",
    "        t_fp = point_index * t_inc_fp\n",
    "        if t_fp < one_half_fp:\n",
    "            local_t_fp = div_fp(t_fp, one_half_fp)\n",
    "            one_minus_t_fp = FIXED_POINT - local_t_fp\n",
    "            red = round_fp_to_int(mul_fp(one_minus_t_fp, float_to_fp(255)))\n",
    "            green = round_fp_to_int(mul_fp(local_t_fp, float_to_fp(255)))\n",
    "            blue = 0\n",
    "        else:\n",
    "            local_t_fp = div_fp(t_fp - one_half_fp, one_half_fp)\n",
    "            one_minus_t_fp = FIXED_POINT - local_t_fp\n",
    "            red = 0\n",
    "            green = round_fp_to_int(mul_fp(one_minus_t_fp, float_to_fp(255)))\n",
    "            blue = round_fp_to_int(mul_fp(local_t_fp, float_to_fp(255)))\n",
    "\n",
    "        red = gate(red, 0, 255)\n",
    "        green = gate(green, 0, 255)\n",
    "        blue = gate(blue, 0, 255)\n",
    "\n",
    "        # Line drawing algorithm (Bresenham's-like logic for fixed point)\n",
    "        if abs(delta_x_fp) > abs(delta_y_fp):  # Iterate along x-axis\n",
    "            line_length = abs(round_fp_to_int(delta_x_fp))\n",
    "            if line_length == 0:\n",
    "                continue\n",
    "            if delta_x_fp > 0:\n",
    "                x_inc_fp = float_to_fp(1.0)\n",
    "                y_inc_fp = div_fp(delta_y_fp, delta_x_fp)  # y_inc per unit x_inc\n",
    "            else:\n",
    "                x_inc_fp = float_to_fp(-1.0)\n",
    "                y_inc_fp = -div_fp(delta_y_fp, delta_x_fp)  # Corrected sign\n",
    "        else:  # Iterate along y-axis\n",
    "            line_length = abs(round_fp_to_int(delta_y_fp))\n",
    "            if line_length == 0:\n",
    "                continue\n",
    "            if delta_y_fp > 0:\n",
    "                y_inc_fp = float_to_fp(1.0)\n",
    "                x_inc_fp = div_fp(delta_x_fp, delta_y_fp)  # x_inc per unit y_inc\n",
    "            else:\n",
    "                y_inc_fp = float_to_fp(-1.0)\n",
    "                x_inc_fp = -div_fp(delta_x_fp, delta_y_fp)  # Corrected sign\n",
    "\n",
    "        for i in range(line_length + 1):\n",
    "            current_x_fp = start_x_fp + mul_fp(\n",
    "                float_to_fp(i),\n",
    "                x_inc_fp if abs(delta_x_fp) > abs(delta_y_fp) else x_inc_fp,\n",
    "            )\n",
    "            current_y_fp = start_y_fp + mul_fp(\n",
    "                float_to_fp(i),\n",
    "                y_inc_fp if abs(delta_x_fp) > abs(delta_y_fp) else y_inc_fp,\n",
    "            )\n",
    "\n",
    "            # For the case where we iterate along y:\n",
    "            if abs(delta_y_fp) >= abs(delta_x_fp):\n",
    "                current_x_fp = start_x_fp + mul_fp(float_to_fp(i), x_inc_fp)\n",
    "                current_y_fp = start_y_fp + mul_fp(float_to_fp(i), y_inc_fp)\n",
    "\n",
    "            x = round_fp_to_int(current_x_fp)\n",
    "            y = round_fp_to_int(current_y_fp)\n",
    "\n",
    "            if (x < 0) or (x >= width) or (y < 0) or (y >= height):\n",
    "                continue\n",
    "\n",
    "            buffer_index = (y * width * NUM_CHANNELS) + (x * NUM_CHANNELS)\n",
    "            if buffer_index + 2 < len(buffer):  # Ensure we are within bounds\n",
    "                buffer[buffer_index + 0] = red\n",
    "                buffer[buffer_index + 1] = green\n",
    "                buffer[buffer_index + 2] = blue\n",
    "\n",
    "    np_buffer = np.frombuffer(buffer, dtype=np.uint8).reshape(\n",
    "        height, width, NUM_CHANNELS\n",
    "    )\n",
    "    return np_buffer\n",
    "\n",
    "\n",
    "# Test rasterization\n",
    "if strokes:\n",
    "    sample_stroke_for_raster = np.random.choice(strokes)\n",
    "    print(f\"Rasterizing a sample stroke: Label {sample_stroke_for_raster['label']}\")\n",
    "    raster = rasterize_stroke(\n",
    "        sample_stroke_for_raster[\"strokePoints\"],\n",
    "        X_RANGE,\n",
    "        Y_RANGE,\n",
    "        IMAGE_WIDTH,\n",
    "        IMAGE_HEIGHT,\n",
    "    )\n",
    "    img = PIL.Image.fromarray(raster).resize(\n",
    "        (256, 256), PIL.Image.NEAREST\n",
    "    )  # Upscale for viewing\n",
    "    display(img)\n",
    "else:\n",
    "    print(\"No strokes to test rasterization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_empty_dir(dirname):\n",
    "    dirpath = Path(dirname)\n",
    "    if dirpath.exists() and dirpath.is_dir():\n",
    "        shutil.rmtree(dirpath)\n",
    "    dirpath.mkdir(\n",
    "        parents=True, exist_ok=False\n",
    "    )  # parents=True in case root_folder doesn't exist\n",
    "\n",
    "\n",
    "def augment_points(points, move_range, scale_range, rotate_range):\n",
    "    \"\"\"Applies random translation, scaling, and rotation to stroke points.\"\"\"\n",
    "    move_x = np.random.uniform(low=-move_range, high=move_range)\n",
    "    move_y = np.random.uniform(low=-move_range, high=move_range)\n",
    "    scale = np.random.uniform(low=1.0 - scale_range, high=1.0 + scale_range)\n",
    "    rotate = np.random.uniform(low=-rotate_range, high=rotate_range)\n",
    "\n",
    "    cos_rot = math.cos(rotate)\n",
    "    sin_rot = math.sin(rotate)\n",
    "\n",
    "    x_axis_x = cos_rot * scale\n",
    "    x_axis_y = sin_rot * scale\n",
    "    y_axis_x = -sin_rot * scale\n",
    "    y_axis_y = cos_rot * scale\n",
    "\n",
    "    new_points = []\n",
    "    for point in points:\n",
    "        old_x = point[\"x\"]\n",
    "        old_y = point[\"y\"]\n",
    "        # Apply rotation and scale first, then translation\n",
    "        rotated_scaled_x = (x_axis_x * old_x) + (\n",
    "            y_axis_x * old_y\n",
    "        )  # Typo in original: x_axis_y should be y_axis_x for y component\n",
    "        rotated_scaled_y = (x_axis_y * old_x) + (\n",
    "            y_axis_y * old_y\n",
    "        )  # Typo in original: y_axis_x should be x_axis_y for x component\n",
    "        # Corrected:\n",
    "        rotated_scaled_x = (cos_rot * old_x - sin_rot * old_y) * scale\n",
    "        rotated_scaled_y = (sin_rot * old_x + cos_rot * old_y) * scale\n",
    "\n",
    "        new_x = rotated_scaled_x + move_x\n",
    "        new_y = rotated_scaled_y + move_y\n",
    "        new_points.append({\"x\": new_x, \"y\": new_y})\n",
    "    return new_points\n",
    "\n",
    "\n",
    "def save_strokes_as_images(\n",
    "    strokes_list, root_folder, width, height, augment_count_per_image\n",
    "):\n",
    "    \"\"\"\n",
    "    Saves strokes as PNG images, organized into subfolders by label.\n",
    "    Applies augmentation to increase dataset size.\n",
    "    \"\"\"\n",
    "    ensure_empty_dir(root_folder)\n",
    "    # Create subdirectories for each label in TARGET_LABELS\n",
    "    for label_str in TARGET_LABELS:\n",
    "        label_path = Path(root_folder, label_str)\n",
    "        ensure_empty_dir(label_path)  # ensure_empty_dir handles creation\n",
    "\n",
    "    label_counts = {label_str: 0 for label_str in TARGET_LABELS}\n",
    "\n",
    "    for stroke in strokes_list:\n",
    "        points = stroke[\"strokePoints\"]\n",
    "        label = str(stroke[\"label\"]).strip().lower()  # Normalize label\n",
    "\n",
    "        if label not in TARGET_LABELS:  # Should not happen if pre-filtered\n",
    "            print(f\"Skipping stroke with unexpected label: {label}\")\n",
    "            continue\n",
    "\n",
    "        if (\n",
    "            not points or len(points) < 2\n",
    "        ):  # Need at least 2 points to make a line segment\n",
    "            print(\n",
    "                f\"Skipping stroke {stroke['filename']}:{stroke['index']} due to insufficient points.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        current_label_count = label_counts[label]\n",
    "        label_counts[label] += 1\n",
    "\n",
    "        # Save original rasterized image\n",
    "        raster = rasterize_stroke(points, X_RANGE, Y_RANGE, width, height)\n",
    "        image = PIL.Image.fromarray(raster)\n",
    "        image.save(Path(root_folder, label, f\"{current_label_count}.png\"))\n",
    "\n",
    "        # Save augmented versions\n",
    "        for i in range(augment_count_per_image):\n",
    "            # Original notebook: move_range=0.0, scale_range=0.1, rotate_range=0.3\n",
    "            # Keeping move_range=0.0 as strokes should be somewhat centered.\n",
    "            augmented_points = augment_points(\n",
    "                points, move_range=0.0, scale_range=0.1, rotate_range=0.3\n",
    "            )\n",
    "            raster_aug = rasterize_stroke(\n",
    "                augmented_points, X_RANGE, Y_RANGE, width, height\n",
    "            )\n",
    "            image_aug = PIL.Image.fromarray(raster_aug)\n",
    "            image_aug.save(Path(root_folder, label, f\"{current_label_count}_a{i}.png\"))\n",
    "\n",
    "    print(f\"Saved images to {root_folder}. Label counts: {label_counts}\")\n",
    "\n",
    "\n",
    "# Shuffle and split data\n",
    "shuffled_strokes = list(strokes)  # Use the filtered 'strokes'\n",
    "np.random.shuffle(shuffled_strokes)\n",
    "\n",
    "# Define dataset split percentages\n",
    "test_percentage = 20  # Increased for smaller dataset\n",
    "validation_percentage = 20\n",
    "train_percentage = 100 - (test_percentage + validation_percentage)\n",
    "\n",
    "# Calculate counts\n",
    "total_filtered_strokes = len(shuffled_strokes)\n",
    "test_count = math.floor((total_filtered_strokes * test_percentage) / 100)\n",
    "validation_count = math.floor((total_filtered_strokes * validation_percentage) / 100)\n",
    "\n",
    "# Split\n",
    "test_strokes = shuffled_strokes[0:test_count]\n",
    "validation_strokes = shuffled_strokes[test_count : (test_count + validation_count)]\n",
    "train_strokes = shuffled_strokes[(test_count + validation_count) :]\n",
    "\n",
    "print(f\"Total strokes for processing: {total_filtered_strokes}\")\n",
    "print(f\"Training strokes: {len(train_strokes)}\")\n",
    "print(f\"Validation strokes: {len(validation_strokes)}\")\n",
    "print(f\"Test strokes: {len(test_strokes)}\")\n",
    "\n",
    "# Define augmentation counts\n",
    "# More augmentation for training, less or none for validation/test\n",
    "# Original used 10 for train and test, 0 for validation.\n",
    "# Let's stick to that for now.\n",
    "AUGMENT_TRAIN = 10\n",
    "AUGMENT_VAL = 0  # No augmentation for validation set\n",
    "AUGMENT_TEST = 0  # Typically no augmentation for test set to get a true measure\n",
    "\n",
    "# Create the image datasets\n",
    "if train_strokes:\n",
    "    save_strokes_as_images(\n",
    "        train_strokes, \"train_0_1\", IMAGE_WIDTH, IMAGE_HEIGHT, AUGMENT_TRAIN\n",
    "    )\n",
    "else:\n",
    "    print(\"No training strokes to save.\")\n",
    "    Path(\"train_0_1\").mkdir(exist_ok=True)  # Create dir anyway for dataset loader\n",
    "\n",
    "if validation_strokes:\n",
    "    save_strokes_as_images(\n",
    "        validation_strokes, \"validation_0_1\", IMAGE_WIDTH, IMAGE_HEIGHT, AUGMENT_VAL\n",
    "    )\n",
    "else:\n",
    "    print(\"No validation strokes to save.\")\n",
    "    Path(\"validation_0_1\").mkdir(exist_ok=True)\n",
    "\n",
    "if test_strokes:\n",
    "    save_strokes_as_images(\n",
    "        test_strokes, \"test_0_1\", IMAGE_WIDTH, IMAGE_HEIGHT, AUGMENT_TEST\n",
    "    )\n",
    "else:\n",
    "    print(\"No test strokes to save.\")\n",
    "    Path(\"test_0_1\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create this as a new Jupyter Notebook cell (Code) - MODIFICATION for Step 6\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create datasets\n",
    "for label in TARGET_LABELS:\n",
    "    Path(f\"train_0_1/{label}\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"validation_0_1/{label}\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"test_0_1/{label}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Initialize class_names variable\n",
    "loaded_class_names = None\n",
    "\n",
    "try:\n",
    "    # For train_ds, capture class_names\n",
    "    train_ds_temp = image_dataset_from_directory(\n",
    "        directory=\"train_0_1\",\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "        shuffle=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    loaded_class_names = train_ds_temp.class_names  # CAPTURE HERE\n",
    "    train_ds = train_ds_temp.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    del train_ds_temp  # Clean up temporary dataset\n",
    "\n",
    "    # For validation_ds, we can assume class names are the same or re-verify\n",
    "    validation_ds_temp = image_dataset_from_directory(\n",
    "        directory=\"validation_0_1\",\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "        shuffle=False,\n",
    "    )\n",
    "    if loaded_class_names and validation_ds_temp.class_names != loaded_class_names:\n",
    "        print(\"Warning: Validation class names differ from training!\")\n",
    "    elif not loaded_class_names:\n",
    "        loaded_class_names = validation_ds_temp.class_names\n",
    "    validation_ds = validation_ds_temp.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    del validation_ds_temp\n",
    "\n",
    "    # For test_ds, similarly\n",
    "    test_ds_temp = image_dataset_from_directory(\n",
    "        directory=\"test_0_1\",\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "        shuffle=False,\n",
    "    )\n",
    "    if loaded_class_names and test_ds_temp.class_names != loaded_class_names:\n",
    "        print(\"Warning: Test class names differ from training/validation!\")\n",
    "    elif not loaded_class_names:\n",
    "        loaded_class_names = test_ds_temp.class_names\n",
    "    test_ds = test_ds_temp.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    del test_ds_temp\n",
    "\n",
    "    if loaded_class_names:\n",
    "        print(\"Datasets loaded successfully.\")\n",
    "        print(f\"Class names captured: {loaded_class_names}\")\n",
    "        if sorted(loaded_class_names) != sorted(TARGET_LABELS):\n",
    "            print(\n",
    "                \"Warning: Captured class names do not match TARGET_LABELS!\"\n",
    "                f\"Captured: {loaded_class_names}, Target: {TARGET_LABELS}\"\n",
    "            )\n",
    "    else:\n",
    "        print(\"Warning: Could not capture class names during dataset loading.\")\n",
    "\n",
    "    # Visualize a few examples from the training dataset\n",
    "    if loaded_class_names:  # Only plot if we have class names\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        for images, labels in train_ds.take(1):\n",
    "            for i in range(min(9, images.shape[0])):\n",
    "                ax = plt.subplot(3, 3, i + 1)\n",
    "                plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "                label_index = np.argmax(labels[i])\n",
    "                plt.title(\n",
    "                    f\"Label: {loaded_class_names[label_index]}\"\n",
    "                )  # Use captured names\n",
    "                plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading datasets: {e}\")\n",
    "    # ... (rest of the error handling remains the same) ...\n",
    "    if \"train_ds\" not in locals():\n",
    "        print(\"Creating dummy empty train_ds.\")\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "            (\n",
    "                np.zeros(\n",
    "                    (0, IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS), dtype=np.float32\n",
    "                ),\n",
    "                np.zeros((0, NUM_CLASSES), dtype=np.float32),\n",
    "            )\n",
    "        ).batch(BATCH_SIZE)\n",
    "    if \"validation_ds\" not in locals():\n",
    "        print(\"Creating dummy empty validation_ds.\")\n",
    "        validation_ds = tf.data.Dataset.from_tensor_slices(\n",
    "            (\n",
    "                np.zeros(\n",
    "                    (0, IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS), dtype=np.float32\n",
    "                ),\n",
    "                np.zeros((0, NUM_CLASSES), dtype=np.float32),\n",
    "            )\n",
    "        ).batch(BATCH_SIZE)\n",
    "    if \"test_ds\" not in locals():\n",
    "        print(\"Creating dummy empty test_ds.\")\n",
    "        test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "            (\n",
    "                np.zeros(\n",
    "                    (0, IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS), dtype=np.float32\n",
    "                ),\n",
    "                np.zeros((0, NUM_CLASSES), dtype=np.float32),\n",
    "            )\n",
    "        ).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes_local):  # Renamed num_classes to avoid conflict\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(16, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)  # Dropout rate can be tuned\n",
    "\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Classifier block\n",
    "    x = layers.Dropout(0.5)(x)  # Dropout before the final dense layer\n",
    "\n",
    "    # For NUM_CLASSES=2 with 'categorical_crossentropy', output layer should have 2 units and softmax\n",
    "    activation = \"softmax\"\n",
    "    units = num_classes_local\n",
    "\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model_input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS)\n",
    "model = make_model(input_shape=model_input_shape, num_classes_local=NUM_CLASSES)\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# Plot the model (optional, but good for visualization)\n",
    "# You might need to install pydot and graphviz:\n",
    "# pip install pydot graphviz\n",
    "try:\n",
    "    display(keras.utils.plot_model(model, show_shapes=True, expand_nested=True))\n",
    "except Exception as e:\n",
    "    print(f\"Could not plot model (is pydot/graphviz installed?): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4260dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30  # Start with a moderate number, can be increased\n",
    "LEARNING_RATE = 1e-3  # 0.001\n",
    "\n",
    "# Callbacks\n",
    "# ModelCheckpoint to save the best model during training\n",
    "checkpoint_filepath = \"checkpoints/best_model_0_1.keras\"  # Use .keras format\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,  # Save the full model\n",
    "    monitor=\"val_accuracy\",  # Monitor validation accuracy\n",
    "    mode=\"max\",  # Mode should be 'max' for accuracy\n",
    "    save_best_only=True,  # Only save if performance improves\n",
    ")\n",
    "\n",
    "# EarlyStopping to prevent overfitting\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",  # Monitor validation loss\n",
    "    patience=10,  # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True,  # Restores model weights from the epoch with the best value of the monitored quantity.\n",
    ")\n",
    "\n",
    "callbacks_list = [model_checkpoint_callback, early_stopping_callback]\n",
    "\n",
    "# Compile the model\n",
    "# For NUM_CLASSES=2 and softmax output, categorical_crossentropy is appropriate\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=\"categorical_crossentropy\",  # Use categorical_crossentropy for one-hot labels\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Check if training data is available\n",
    "# train_ds.cardinality() returns the number of batches. tf.data.UNKNOWN_CARDINALITY if it's infinite or can't be determined.\n",
    "# train_ds.reduce(0, lambda x, _: x + 1) would count elements but can be slow for large datasets.\n",
    "# A simple check is to see if we can take at least one batch.\n",
    "try:\n",
    "    _ = next(iter(train_ds))\n",
    "    has_train_data = True\n",
    "except StopIteration:\n",
    "    has_train_data = False\n",
    "\n",
    "if has_train_data:\n",
    "    print(f\"Starting training for {EPOCHS} epochs...\")\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks_list,\n",
    "        validation_data=validation_ds,\n",
    "    )\n",
    "\n",
    "    # Plot training history\n",
    "    if history and history.history:\n",
    "        acc = history.history[\"accuracy\"]\n",
    "        val_acc = history.history[\"val_accuracy\"]\n",
    "        loss = history.history[\"loss\"]\n",
    "        val_loss = history.history[\"val_loss\"]\n",
    "        epochs_range = range(len(acc))\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
    "        plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
    "        plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.title(\"Training and Validation Loss\")\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Skipping training as no training data was found or loaded.\")\n",
    "    history = None  # Ensure history object exists\n",
    "\n",
    "# Load the best model saved by ModelCheckpoint\n",
    "if os.path.exists(checkpoint_filepath) and has_train_data:\n",
    "    print(f\"Loading best model from {checkpoint_filepath}\")\n",
    "    model = keras.models.load_model(checkpoint_filepath)\n",
    "else:\n",
    "    print(\n",
    "        \"Best model checkpoint not found or training was skipped. Using the model from the last training epoch (if any).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ea61d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if test data is available\n",
    "try:\n",
    "    _ = next(iter(test_ds))\n",
    "    has_test_data = True\n",
    "except StopIteration:\n",
    "    has_test_data = False\n",
    "\n",
    "if has_test_data:\n",
    "    print(\"Evaluating model on the test dataset...\")\n",
    "    loss, accuracy = model.evaluate(test_ds)\n",
    "    print(f\"Test Loss: {loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"Skipping evaluation as no test data was found or loaded.\")\n",
    "    accuracy = 0.0  # Default if no test data\n",
    "\n",
    "\n",
    "# Prediction function (similar to original, adapted for tf.data.Dataset)\n",
    "def predict_image_keras(\n",
    "    keras_model, image_path, class_names_list_param\n",
    "):  # Renamed param\n",
    "    img = keras.preprocessing.image.load_img(\n",
    "        image_path, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "    )\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = keras_model.predict(img_array, verbose=0).flatten()\n",
    "    predicted_label_index = np.argmax(predictions)\n",
    "    predicted_score = predictions[predicted_label_index]\n",
    "    # Ensure class_names_list_param is valid and index is within bounds\n",
    "    if class_names_list_param and 0 <= predicted_label_index < len(\n",
    "        class_names_list_param\n",
    "    ):\n",
    "        predicted_label_name = class_names_list_param[predicted_label_index]\n",
    "    else:\n",
    "        predicted_label_name = f\"Unknown (Index {predicted_label_index})\"  # Fallback\n",
    "    return (predicted_label_name, predicted_label_index, predicted_score)\n",
    "\n",
    "\n",
    "# Test with a few images from the test set (if available)\n",
    "SCORE_THRESHOLD = 0.75  # From original notebook\n",
    "correct_count = 0\n",
    "wrong_count = 0\n",
    "discarded_count = 0\n",
    "\n",
    "if has_test_data and loaded_class_names:  # Check 'loaded_class_names'\n",
    "    print(f\"\\nDetailed predictions on test images (threshold: {SCORE_THRESHOLD}):\")\n",
    "    for label_str in loaded_class_names:  # Iterate using 'loaded_class_names'\n",
    "        label_dir = Path(\"test_0_1\") / label_str\n",
    "        for image_file in glob.glob(str(label_dir / \"*.png\")):\n",
    "            true_label_name = label_str\n",
    "\n",
    "            # Pass 'loaded_class_names' to the prediction function\n",
    "            pred_label_name, pred_label_idx, score = predict_image_keras(\n",
    "                model, image_file, loaded_class_names\n",
    "            )\n",
    "\n",
    "            if score < SCORE_THRESHOLD:\n",
    "                discarded_count += 1\n",
    "                continue\n",
    "\n",
    "            if pred_label_name == true_label_name:\n",
    "                correct_count += 1\n",
    "            else:\n",
    "                wrong_count += 1\n",
    "                print(\n",
    "                    f\"File: {Path(image_file).name} - Expected: {true_label_name}, \"\n",
    "                    f\"Predicted: {pred_label_name} with score {score:.4f}\"\n",
    "                )\n",
    "                display(Image(filename=image_file, width=100))\n",
    "\n",
    "    if (correct_count + wrong_count) > 0:\n",
    "        detailed_accuracy = (correct_count / (correct_count + wrong_count)) * 100\n",
    "        print(\n",
    "            f\"\\nDetailed Test Accuracy (above threshold): {detailed_accuracy:.1f}% \"\n",
    "            f\"(Correct: {correct_count}, Wrong: {wrong_count}, Discarded: {discarded_count})\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"No predictions made above the score threshold, or no test files found for detailed check.\"\n",
    "        )\n",
    "else:\n",
    "    print(\n",
    "        \"Skipping detailed test predictions as no test data or class names are available (check 'loaded_class_names').\"\n",
    "    )\n",
    "\n",
    "# Save the trained Keras model (final version after potential loading of best checkpoint)\n",
    "model.save(SAVED_MODEL_FILENAME + \".keras\")  # Using .keras format\n",
    "print(f\"Keras model saved to {SAVED_MODEL_FILENAME}.keras\")\n",
    "\n",
    "# Also save in the SavedModel directory format if needed for TFLite conversion later\n",
    "model.export(SAVED_MODEL_FILENAME)  # This saves in TF SavedModel format\n",
    "print(\n",
    "    f\"Keras model also saved in SavedModel format to directory: {SAVED_MODEL_FILENAME}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the SavedModel directory exists from the previous step\n",
    "saved_model_dir = SAVED_MODEL_FILENAME  # e.g., \"saved_model_0_1\"\n",
    "if not Path(saved_model_dir).is_dir():\n",
    "    print(f\"Error: SavedModel directory '{saved_model_dir}' not found.\")\n",
    "    print(\"Please ensure Step 9 completed successfully and created this directory.\")\n",
    "    # As a fallback, try to load from the .keras file if the directory is missing\n",
    "    # and re-export. This is not ideal but can help if a step was missed.\n",
    "    keras_model_path = SAVED_MODEL_FILENAME + \".keras\"\n",
    "    if Path(keras_model_path).exists():\n",
    "        print(\n",
    "            f\"Attempting to load from {keras_model_path} and re-export to {saved_model_dir}...\"\n",
    "        )\n",
    "        try:\n",
    "            model_to_convert = keras.models.load_model(keras_model_path)\n",
    "            if hasattr(model_to_convert, \"export\") and callable(\n",
    "                getattr(model_to_convert, \"export\")\n",
    "            ):\n",
    "                model_to_convert.export(saved_model_dir)\n",
    "            else:\n",
    "                model_to_convert.save(saved_model_dir)  # Older TF\n",
    "            print(f\"Re-exported model to {saved_model_dir}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to re-export model: {e}\")\n",
    "            raise ValueError(\n",
    "                f\"SavedModel directory '{saved_model_dir}' is required for TFLite conversion.\"\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"SavedModel directory '{saved_model_dir}' is required and could not be recreated.\"\n",
    "        )\n",
    "\n",
    "\n",
    "# --- 1. Convert to Float TFLite Model ---\n",
    "print(f\"\\nConverting to Float TFLite model from: {saved_model_dir}\")\n",
    "converter_float = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "# No specific optimizations for the basic float model yet\n",
    "# converter_float.optimizations = [] # Default\n",
    "model_float_tflite = converter_float.convert()\n",
    "\n",
    "# Save the float TFLite model to disk\n",
    "with open(FLOAT_TFL_MODEL_FILENAME, \"wb\") as f:\n",
    "    f.write(model_float_tflite)\n",
    "print(f\"Float TFLite model saved to: {FLOAT_TFL_MODEL_FILENAME}\")\n",
    "\n",
    "\n",
    "# --- 2. Convert to Quantized TFLite Model (INT8) ---\n",
    "print(f\"\\nConverting to Quantized INT8 TFLite model from: {saved_model_dir}\")\n",
    "\n",
    "\n",
    "# Define a representative dataset generator\n",
    "# This dataset is used to calibrate the quantization parameters (scale and zero-point)\n",
    "# for the activations in the model. It should reflect the input data distribution.\n",
    "# We'll use a portion of our training dataset.\n",
    "def representative_dataset_gen():\n",
    "    # Use a subset of the training dataset for calibration\n",
    "    # Taking a few batches should be sufficient.\n",
    "    # Ensure images are preprocessed (e.g., scaled to [0,1] or [-1,1] if your model expects that)\n",
    "    # The Rescaling layer in the model handles 0-255 to 0-1, so raw images are fine here.\n",
    "    num_calibration_steps = 100  # Number of samples for calibration\n",
    "    calibration_ds = (\n",
    "        train_ds.unbatch().take(num_calibration_steps).batch(1)\n",
    "    )  # Take individual images\n",
    "\n",
    "    for image_batch, _ in calibration_ds:\n",
    "        # Input to the TFLite model will be float32, even for int8 quantization\n",
    "        # The converter handles the quantization of the input layer based on its type.\n",
    "        yield [\n",
    "            image_batch\n",
    "        ]  # Yield a list of inputs, as the model might have multiple inputs\n",
    "\n",
    "\n",
    "# Create a new converter for quantization\n",
    "converter_quant = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "\n",
    "# Set optimization strategy to default (includes quantization)\n",
    "converter_quant.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Provide the representative dataset\n",
    "converter_quant.representative_dataset = representative_dataset_gen\n",
    "\n",
    "# Enforce integer-only quantization for inputs and outputs (for full INT8 model)\n",
    "# This is crucial for microcontrollers.\n",
    "converter_quant.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter_quant.inference_input_type = tf.int8  # Model input will be int8\n",
    "converter_quant.inference_output_type = tf.int8  # Model output will be int8\n",
    "\n",
    "# Perform the conversion\n",
    "try:\n",
    "    model_quantized_tflite = converter_quant.convert()\n",
    "\n",
    "    # Save the quantized TFLite model to disk\n",
    "    with open(QUANTIZED_TFL_MODEL_FILENAME, \"wb\") as f:\n",
    "        f.write(model_quantized_tflite)\n",
    "    print(f\"Quantized INT8 TFLite model saved to: {QUANTIZED_TFL_MODEL_FILENAME}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during INT8 quantization: {e}\")\n",
    "    print(\n",
    "        \"This can happen if some operations in the model are not supported for INT8 quantization,\"\n",
    "    )\n",
    "    print(\"or if the representative dataset is problematic.\")\n",
    "    print(\n",
    "        \"Consider using tf.lite.OpsSet.TFLITE_BUILTINS (allows float fallbacks) if full INT8 is not achievable,\"\n",
    "    )\n",
    "    print(\"or review your model architecture for INT8 compatibility.\")\n",
    "    model_quantized_tflite = None  # Ensure it's None if conversion failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef6766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tflite(tflite_model_content, image_path, class_names_list_param):\n",
    "    \"\"\"\n",
    "    Performs inference using a TFLite model and returns predicted label and score.\n",
    "    \"\"\"\n",
    "    # Load the image and preprocess it\n",
    "    img = keras.preprocessing.image.load_img(\n",
    "        image_path, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "    )\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0).astype(\n",
    "        np.float32\n",
    "    )  # Ensure float32 for initial input\n",
    "\n",
    "    # Initialize the TFLite interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model_content)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "    # Check if input quantization is required\n",
    "    # If input_type is int8, we need to quantize the float32 input image\n",
    "    if input_details[\"dtype\"] == np.int8:\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "        if (input_scale, input_zero_point) != (\n",
    "            0.0,\n",
    "            0,\n",
    "        ):  # Check if quantization params are valid\n",
    "            img_array = (img_array / input_scale) + input_zero_point\n",
    "            img_array = img_array.astype(input_details[\"dtype\"])\n",
    "        else:  # If no valid quantization params, but dtype is int8, this is unusual.\n",
    "            # This might happen if the input layer itself wasn't properly quantized.\n",
    "            # For safety, we might cast, but it's better if the model is correctly quantized.\n",
    "            print(\n",
    "                \"Warning: Input is int8 but scale/zero_point are default. Casting directly.\"\n",
    "            )\n",
    "            img_array = img_array.astype(input_details[\"dtype\"])\n",
    "\n",
    "    # Set the tensor to point to the input data to be inferred\n",
    "    interpreter.set_tensor(input_details[\"index\"], img_array)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get the output tensor\n",
    "    output_data = interpreter.get_tensor(output_details[\"index\"])[0]  # Batch size is 1\n",
    "\n",
    "    # Check if output dequantization is required\n",
    "    if output_details[\"dtype\"] == np.int8:\n",
    "        output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "        if (output_scale, output_zero_point) != (0.0, 0):\n",
    "            output_data = output_data.astype(np.float32)\n",
    "            output_data = (output_data - output_zero_point) * output_scale\n",
    "        # If no valid dequant params, but dtype is int8, output is likely still in quantized range.\n",
    "        # For softmax, this means values are likely 0-255 or -128 to 127.\n",
    "        # Argmax will still work, but scores won't be probabilities unless dequantized.\n",
    "\n",
    "    # Get the predicted label index and score\n",
    "    predicted_label_index = np.argmax(output_data)\n",
    "    predicted_score = output_data[\n",
    "        predicted_label_index\n",
    "    ]  # This is the raw score from the output layer\n",
    "\n",
    "    # If the output was softmax and then quantized, the scores might not sum to 1\n",
    "    # after dequantization. For just getting the top class, this is fine.\n",
    "    # If you need probabilities, ensure the dequantization is correct or apply softmax again.\n",
    "    # For this classification, we primarily care about the argmax.\n",
    "\n",
    "    if class_names_list_param and 0 <= predicted_label_index < len(\n",
    "        class_names_list_param\n",
    "    ):\n",
    "        predicted_label_name = class_names_list_param[predicted_label_index]\n",
    "    else:\n",
    "        predicted_label_name = f\"Unknown (Index {predicted_label_index})\"\n",
    "\n",
    "    return (predicted_label_name, predicted_label_index, predicted_score)\n",
    "\n",
    "\n",
    "def evaluate_tflite_model(\n",
    "    model_content, model_name, class_names_eval, score_threshold_eval\n",
    "):\n",
    "    if model_content is None:\n",
    "        print(f\"Skipping evaluation for {model_name} as model content is None.\")\n",
    "        return 0.0, 0, 0, 0\n",
    "\n",
    "    print(\n",
    "        f\"\\nEvaluating {model_name} on test images (threshold: {score_threshold_eval}):\"\n",
    "    )\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    discarded = 0\n",
    "\n",
    "    if not has_test_data or not class_names_eval:\n",
    "        print(f\"Skipping evaluation for {model_name}: No test data or class names.\")\n",
    "        return 0.0, 0, 0, 0\n",
    "\n",
    "    for label_str in class_names_eval:\n",
    "        label_dir = Path(\"test_0_1\") / label_str\n",
    "        for image_file in glob.glob(str(label_dir / \"*.png\")):\n",
    "            true_label_name = label_str\n",
    "\n",
    "            pred_label_name, _, score = predict_tflite(\n",
    "                model_content, image_file, class_names_eval\n",
    "            )\n",
    "\n",
    "            if score < score_threshold_eval:\n",
    "                discarded += 1\n",
    "                continue\n",
    "\n",
    "            if pred_label_name == true_label_name:\n",
    "                correct += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "                # print(f\"MISCLASSIFIED ({model_name}): {Path(image_file).name} - Expected: {true_label_name}, Predicted: {pred_label_name}, Score: {score:.4f}\")\n",
    "                # display(Image(filename=image_file, width=60))\n",
    "\n",
    "    if (correct + wrong) > 0:\n",
    "        accuracy = (correct / (correct + wrong)) * 100\n",
    "        print(\n",
    "            f\"{model_name} - Accuracy (above threshold): {accuracy:.1f}% \"\n",
    "            f\"(Correct: {correct}, Wrong: {wrong}, Discarded: {discarded})\"\n",
    "        )\n",
    "    else:\n",
    "        accuracy = 0.0\n",
    "        print(\n",
    "            f\"{model_name} - No predictions made above threshold or no test files. \"\n",
    "            f\"(Correct: {correct}, Wrong: {wrong}, Discarded: {discarded})\"\n",
    "        )\n",
    "    return accuracy, correct, wrong, discarded\n",
    "\n",
    "\n",
    "# Evaluate Float TFLite model\n",
    "if Path(FLOAT_TFL_MODEL_FILENAME).exists():\n",
    "    with open(FLOAT_TFL_MODEL_FILENAME, \"rb\") as f:\n",
    "        model_float_tflite_content = f.read()\n",
    "    evaluate_tflite_model(\n",
    "        model_float_tflite_content,\n",
    "        \"Float TFLite Model\",\n",
    "        loaded_class_names,  # Use the class names captured in Step 6\n",
    "        SCORE_THRESHOLD,\n",
    "    )\n",
    "else:\n",
    "    print(f\"{FLOAT_TFL_MODEL_FILENAME} not found. Skipping its evaluation.\")\n",
    "\n",
    "# Evaluate Quantized INT8 TFLite model\n",
    "if model_quantized_tflite is not None and Path(QUANTIZED_TFL_MODEL_FILENAME).exists():\n",
    "    # model_quantized_tflite already holds the content if conversion was successful\n",
    "    evaluate_tflite_model(\n",
    "        model_quantized_tflite,\n",
    "        \"Quantized INT8 TFLite Model\",\n",
    "        loaded_class_names,  # Use the class names captured in Step 6\n",
    "        SCORE_THRESHOLD,\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        f\"{QUANTIZED_TFL_MODEL_FILENAME} not found or quantization failed. Skipping its evaluation.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_dir_size(dir_path_str):\n",
    "    \"\"\"Calculates the total size of a directory.\"\"\"\n",
    "    dir_path = Path(dir_path_str)\n",
    "    total_size = 0\n",
    "    if not dir_path.is_dir():\n",
    "        return 0\n",
    "    for entry in dir_path.rglob(\"*\"):  # rglob for recursive\n",
    "        if entry.is_file():\n",
    "            total_size += entry.stat().st_size\n",
    "    return total_size\n",
    "\n",
    "\n",
    "# Calculate sizes\n",
    "size_tf_savedmodel = get_dir_size(SAVED_MODEL_FILENAME)  # Directory\n",
    "\n",
    "size_float_tflite = 0\n",
    "if Path(FLOAT_TFL_MODEL_FILENAME).exists():\n",
    "    size_float_tflite = Path(FLOAT_TFL_MODEL_FILENAME).stat().st_size\n",
    "\n",
    "size_quantized_tflite = 0\n",
    "if Path(QUANTIZED_TFL_MODEL_FILENAME).exists():\n",
    "    size_quantized_tflite = Path(QUANTIZED_TFL_MODEL_FILENAME).stat().st_size\n",
    "\n",
    "# Prepare data for DataFrame\n",
    "size_data = []\n",
    "size_data.append([\"Keras SavedModel (directory)\", f\"{size_tf_savedmodel} bytes\", \"\"])\n",
    "\n",
    "if size_float_tflite > 0:\n",
    "    reduction_from_tf = size_tf_savedmodel - size_float_tflite\n",
    "    reduction_percent_tf = (\n",
    "        (reduction_from_tf / size_tf_savedmodel * 100) if size_tf_savedmodel > 0 else 0\n",
    "    )\n",
    "    size_data.append(\n",
    "        [\n",
    "            \"Float TFLite Model\",\n",
    "            f\"{size_float_tflite} bytes\",\n",
    "            f\"(Reduced by {reduction_from_tf} bytes / {reduction_percent_tf:.1f}% vs SavedModel)\",\n",
    "        ]\n",
    "    )\n",
    "    if size_quantized_tflite > 0:\n",
    "        reduction_from_float = size_float_tflite - size_quantized_tflite\n",
    "        reduction_percent_float = (\n",
    "            (reduction_from_float / size_float_tflite * 100)\n",
    "            if size_float_tflite > 0\n",
    "            else 0\n",
    "        )\n",
    "        size_data.append(\n",
    "            [\n",
    "                \"Quantized INT8 TFLite Model\",\n",
    "                f\"{size_quantized_tflite} bytes\",\n",
    "                f\"(Reduced by {reduction_from_float} bytes / {reduction_percent_float:.1f}% vs Float TFLite)\",\n",
    "            ]\n",
    "        )\n",
    "elif size_quantized_tflite > 0:  # Only quantized exists\n",
    "    reduction_from_tf_q = size_tf_savedmodel - size_quantized_tflite\n",
    "    reduction_percent_tf_q = (\n",
    "        (reduction_from_tf_q / size_tf_savedmodel * 100)\n",
    "        if size_tf_savedmodel > 0\n",
    "        else 0\n",
    "    )\n",
    "    size_data.append(\n",
    "        [\n",
    "            \"Quantized INT8 TFLite Model\",\n",
    "            f\"{size_quantized_tflite} bytes\",\n",
    "            f\"(Reduced by {reduction_from_tf_q} bytes / {reduction_percent_tf_q:.1f}% vs SavedModel)\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# Display comparison table\n",
    "size_df = pd.DataFrame(size_data, columns=[\"Model Type\", \"Size\", \"Reduction\"])\n",
    "display(size_df.set_index(\"Model Type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfcd196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create this as a new Jupyter Notebook cell (Code) - Full Step 13 with Python replacement\n",
    "\n",
    "# Check if the quantized model file exists\n",
    "if Path(QUANTIZED_TFL_MODEL_FILENAME).exists():\n",
    "    print(\"Attempting to install/update xxd...\")\n",
    "    try:\n",
    "        result_update = os.system(\"apt-get update -qq > /dev/null 2>&1\")\n",
    "        # if result_update != 0: print(\"apt-get update might have had issues.\") # Optional: less verbose\n",
    "        result_install = os.system(\"apt-get install -y -qq xxd > /dev/null 2>&1\")\n",
    "        # if result_install != 0: print(\"apt-get install xxd might have had issues or xxd is already up-to-date.\")\n",
    "        # else: print(\"xxd should be available.\") # Optional: less verbose\n",
    "        print(\"xxd check complete.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not run apt-get (not a Linux system or no permissions?): {e}\")\n",
    "        print(\n",
    "            \"Skipping C source file generation. Manual xxd execution might be needed.\"\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"\\nConverting {QUANTIZED_TFL_MODEL_FILENAME} to C source file: {TFL_CC_MODEL_FILENAME}\"\n",
    "    )\n",
    "\n",
    "    xxd_command = f\"xxd -i {QUANTIZED_TFL_MODEL_FILENAME} > {TFL_CC_MODEL_FILENAME}\"\n",
    "    if os.system(xxd_command) == 0:\n",
    "        print(f\"Successfully created C source file: {TFL_CC_MODEL_FILENAME}\")\n",
    "\n",
    "        generated_var_name = None\n",
    "        try:\n",
    "            with open(TFL_CC_MODEL_FILENAME, \"r\") as f_cc:\n",
    "                for line in f_cc:\n",
    "                    if \"unsigned char\" in line and \"[]\" in line:\n",
    "                        parts = line.split(\"unsigned char\")[1].split(\"[]\")[0].strip()\n",
    "                        generated_var_name = parts\n",
    "                        break\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading C file to detect variable name: {e}\")\n",
    "\n",
    "        if generated_var_name:\n",
    "            print(f\"Detected generated variable base name: {generated_var_name}\")\n",
    "            new_var_base_name = \"g_magic_wand_model_data\"  # Target variable name\n",
    "\n",
    "            try:\n",
    "                with open(TFL_CC_MODEL_FILENAME, \"r\") as file:\n",
    "                    content = file.read()\n",
    "\n",
    "                # Perform replacements\n",
    "                # 1. Replace the array definition: \"unsigned char old_var_name[]\"\n",
    "                content = content.replace(\n",
    "                    f\"unsigned char {generated_var_name}[]\",\n",
    "                    f\"unsigned char {new_var_base_name}[]\",\n",
    "                )\n",
    "                # 2. Replace the length variable: \"unsigned int old_var_name_len\"\n",
    "                content = content.replace(\n",
    "                    f\"unsigned int {generated_var_name}_len\",\n",
    "                    f\"unsigned int {new_var_base_name}_len\",\n",
    "                )\n",
    "\n",
    "                with open(TFL_CC_MODEL_FILENAME, \"w\") as file:\n",
    "                    file.write(content)\n",
    "\n",
    "                print(\n",
    "                    \"Successfully updated variable names in C source file using Python.\"\n",
    "                )\n",
    "\n",
    "                print(f\"\\nTail of {TFL_CC_MODEL_FILENAME}:\")\n",
    "                os.system(f\"tail -n 15 {TFL_CC_MODEL_FILENAME}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error updating variable names using Python string replacement: {e}\"\n",
    "                )\n",
    "        else:\n",
    "            print(\n",
    "                \"Could not automatically detect generated variable name in .cc file. Skipping renaming.\"\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            f\"Error running xxd. C source file '{TFL_CC_MODEL_FILENAME}' might not be created or is empty.\"\n",
    "        )\n",
    "        print(\"Ensure xxd is installed and in your PATH.\")\n",
    "else:\n",
    "    print(\n",
    "        f\"{QUANTIZED_TFL_MODEL_FILENAME} not found. Skipping C source file generation.\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
