{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c781f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "SAVED_MODEL_FILENAME = \"model\"\n",
    "TFL_CC_MODEL_FILENAME = \"model.cc\"\n",
    "FLOAT_TFL_MODEL_FILENAME = \"float_model.tfl\"\n",
    "QUANTIZED_TFL_MODEL_FILENAME = \"quantized_model.tfl\"\n",
    "\n",
    "# Image properties\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_HEIGHT = 32\n",
    "NUM_CHANNELS = 3\n",
    "\n",
    "# Fixed-point arithmetic (for rasterization)\n",
    "FIXED_POINT = 4096\n",
    "\n",
    "# Data ranges for rasterization\n",
    "X_RANGE = 0.8  # Max expected x-coordinate deviation from center\n",
    "Y_RANGE = 0.8  # Max expected y-coordinate deviation from center\n",
    "\n",
    "LABELS = [\n",
    "    \"0\",  # |\n",
    "    \"1\",  # —\n",
    "    \"2\",  # △\n",
    "    \"3\",  # ◯\n",
    "    \"4\",  # □\n",
    "]\n",
    "NUM_CLASSES = len(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af00b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "strokes = []\n",
    "\n",
    "for filename in glob.glob(\"data/*.json\"):\n",
    "    with open(filename, \"r\") as file:\n",
    "        file_contents = file.read()\n",
    "    try:\n",
    "        file_data = json.loads(file_contents)\n",
    "        for _, stroke in enumerate(file_data[\"strokes\"]):\n",
    "            stroke[\"filename\"] = filename\n",
    "            strokes.append(stroke)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Warning: Could not decode JSON from {filename}\")\n",
    "    except KeyError:\n",
    "        print(f\"Warning: 'strokes' key not found in {filename}\")\n",
    "\n",
    "print(f\"Total strokes loaded: {len(strokes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbf215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul_fp(a, b):\n",
    "    return (a * b) // FIXED_POINT\n",
    "\n",
    "\n",
    "def div_fp(a, b):\n",
    "    if b == 0:\n",
    "        b = 1\n",
    "    return (a * FIXED_POINT) // b\n",
    "\n",
    "\n",
    "def float_to_fp(a):\n",
    "    return math.floor(a * FIXED_POINT)\n",
    "\n",
    "\n",
    "def norm_to_coord_fp(a, range_fp, half_size_fp):\n",
    "    a_fp = float_to_fp(a)\n",
    "    norm_fp = div_fp(a_fp, range_fp)\n",
    "    return mul_fp(norm_fp, half_size_fp) + half_size_fp\n",
    "\n",
    "\n",
    "def round_fp_to_int(a):\n",
    "    return math.floor((a + (FIXED_POINT // 2)) / FIXED_POINT)\n",
    "\n",
    "\n",
    "def gate(a, min_val, max_val):\n",
    "    if a < min_val:\n",
    "        return min_val\n",
    "    elif a > max_val:\n",
    "        return max_val\n",
    "    else:\n",
    "        return a\n",
    "\n",
    "\n",
    "def rasterize_stroke(stroke_points, x_range, y_range, width, height):\n",
    "    \"\"\"\n",
    "    Rasterizes stroke points into an image buffer with time encoded as color.\n",
    "    x_range: The expected maximum deviation of x-coordinates from the center (e.g., 0.5 means coords range from -0.5 to 0.5)\n",
    "    y_range: Similar for y-coordinates.\n",
    "    width: Output image width in pixels.\n",
    "    height: Output image height in pixels.\n",
    "    \"\"\"\n",
    "    if not stroke_points or len(stroke_points) < 2:\n",
    "        return np.zeros((height, width, NUM_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "    buffer_byte_count = height * width * NUM_CHANNELS\n",
    "    buffer = bytearray(buffer_byte_count)\n",
    "\n",
    "    width_fp = float_to_fp(width)\n",
    "    height_fp = float_to_fp(height)\n",
    "    half_width_fp = width_fp // 2\n",
    "    half_height_fp = height_fp // 2\n",
    "    x_range_fp = float_to_fp(x_range)\n",
    "    y_range_fp = float_to_fp(y_range)\n",
    "\n",
    "    num_segments = len(stroke_points) - 1\n",
    "    if num_segments == 0:  # single point, can't draw lines\n",
    "        return np.frombuffer(buffer, dtype=np.uint8).reshape(\n",
    "            height, width, NUM_CHANNELS\n",
    "        )\n",
    "\n",
    "    t_inc_fp = FIXED_POINT // num_segments if num_segments > 0 else FIXED_POINT\n",
    "\n",
    "    one_half_fp = FIXED_POINT // 2\n",
    "\n",
    "    for point_index in range(num_segments):\n",
    "        start_point = stroke_points[point_index]\n",
    "        end_point = stroke_points[point_index + 1]\n",
    "\n",
    "        start_x_fp = norm_to_coord_fp(start_point[\"x\"], x_range_fp, half_width_fp)\n",
    "        start_y_fp = norm_to_coord_fp(-start_point[\"y\"], y_range_fp, half_height_fp)\n",
    "        end_x_fp = norm_to_coord_fp(end_point[\"x\"], x_range_fp, half_width_fp)\n",
    "        end_y_fp = norm_to_coord_fp(-end_point[\"y\"], y_range_fp, half_height_fp)\n",
    "\n",
    "        delta_x_fp = end_x_fp - start_x_fp\n",
    "        delta_y_fp = end_y_fp - start_y_fp\n",
    "\n",
    "        # Determine color based on progress through the stroke\n",
    "        t_fp = point_index * t_inc_fp\n",
    "        if t_fp < one_half_fp:\n",
    "            local_t_fp = div_fp(t_fp, one_half_fp)\n",
    "            one_minus_t_fp = FIXED_POINT - local_t_fp\n",
    "            red = round_fp_to_int(mul_fp(one_minus_t_fp, float_to_fp(255)))\n",
    "            green = round_fp_to_int(mul_fp(local_t_fp, float_to_fp(255)))\n",
    "            blue = 0\n",
    "        else:\n",
    "            local_t_fp = div_fp(t_fp - one_half_fp, one_half_fp)\n",
    "            one_minus_t_fp = FIXED_POINT - local_t_fp\n",
    "            red = 0\n",
    "            green = round_fp_to_int(mul_fp(one_minus_t_fp, float_to_fp(255)))\n",
    "            blue = round_fp_to_int(mul_fp(local_t_fp, float_to_fp(255)))\n",
    "\n",
    "        red = gate(red, 0, 255)\n",
    "        green = gate(green, 0, 255)\n",
    "        blue = gate(blue, 0, 255)\n",
    "\n",
    "        # Line drawing algorithm (Bresenham's-like logic for fixed point)\n",
    "        if abs(delta_x_fp) > abs(delta_y_fp):\n",
    "            line_length = abs(round_fp_to_int(delta_x_fp))\n",
    "            if line_length == 0:\n",
    "                continue\n",
    "            if delta_x_fp > 0:\n",
    "                x_inc_fp = float_to_fp(1.0)\n",
    "                y_inc_fp = div_fp(delta_y_fp, delta_x_fp)\n",
    "            else:\n",
    "                x_inc_fp = float_to_fp(-1.0)\n",
    "                y_inc_fp = -div_fp(delta_y_fp, delta_x_fp)\n",
    "        else:\n",
    "            line_length = abs(round_fp_to_int(delta_y_fp))\n",
    "            if line_length == 0:\n",
    "                continue\n",
    "            if delta_y_fp > 0:\n",
    "                y_inc_fp = float_to_fp(1.0)\n",
    "                x_inc_fp = div_fp(delta_x_fp, delta_y_fp)\n",
    "            else:\n",
    "                y_inc_fp = float_to_fp(-1.0)\n",
    "                x_inc_fp = -div_fp(delta_x_fp, delta_y_fp)\n",
    "\n",
    "        for i in range(line_length + 1):\n",
    "            current_x_fp = start_x_fp + mul_fp(\n",
    "                float_to_fp(i),\n",
    "                x_inc_fp if abs(delta_x_fp) > abs(delta_y_fp) else x_inc_fp,\n",
    "            )\n",
    "            current_y_fp = start_y_fp + mul_fp(\n",
    "                float_to_fp(i),\n",
    "                y_inc_fp if abs(delta_x_fp) > abs(delta_y_fp) else y_inc_fp,\n",
    "            )\n",
    "\n",
    "            # For the case where we iterate along y:\n",
    "            if abs(delta_y_fp) >= abs(delta_x_fp):\n",
    "                current_x_fp = start_x_fp + mul_fp(float_to_fp(i), x_inc_fp)\n",
    "                current_y_fp = start_y_fp + mul_fp(float_to_fp(i), y_inc_fp)\n",
    "\n",
    "            x = round_fp_to_int(current_x_fp)\n",
    "            y = round_fp_to_int(current_y_fp)\n",
    "\n",
    "            if (x < 0) or (x >= width) or (y < 0) or (y >= height):\n",
    "                continue\n",
    "\n",
    "            buffer_index = (y * width * NUM_CHANNELS) + (x * NUM_CHANNELS)\n",
    "            if buffer_index + 2 < len(buffer):\n",
    "                buffer[buffer_index + 0] = red\n",
    "                buffer[buffer_index + 1] = green\n",
    "                buffer[buffer_index + 2] = blue\n",
    "\n",
    "    np_buffer = np.frombuffer(buffer, dtype=np.uint8).reshape(\n",
    "        height, width, NUM_CHANNELS\n",
    "    )\n",
    "    return np_buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2309f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import PIL\n",
    "\n",
    "\n",
    "def ensure_empty_dir(dirname):\n",
    "    dirpath = Path(dirname)\n",
    "    if dirpath.exists() and dirpath.is_dir():\n",
    "        shutil.rmtree(dirpath)\n",
    "    dirpath.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "\n",
    "def augment_points(points, move_range, scale_range, rotate_range):\n",
    "    \"\"\"Applies random translation, scaling, and rotation to stroke points.\"\"\"\n",
    "    move_x = np.random.uniform(low=-move_range, high=move_range)\n",
    "    move_y = np.random.uniform(low=-move_range, high=move_range)\n",
    "    scale = np.random.uniform(low=1.0 - scale_range, high=1.0 + scale_range)\n",
    "    rotate = np.random.uniform(low=-rotate_range, high=rotate_range)\n",
    "\n",
    "    cos_rot = math.cos(rotate)\n",
    "    sin_rot = math.sin(rotate)\n",
    "\n",
    "    x_axis_x = cos_rot * scale\n",
    "    x_axis_y = sin_rot * scale\n",
    "    y_axis_x = -sin_rot * scale\n",
    "    y_axis_y = cos_rot * scale\n",
    "\n",
    "    new_points = []\n",
    "    for point in points:\n",
    "        old_x = point[\"x\"]\n",
    "        old_y = point[\"y\"]\n",
    "        # Apply rotation and scale first, then translation\n",
    "        rotated_scaled_x = (x_axis_x * old_x) + (\n",
    "            y_axis_x * old_y\n",
    "        )  # Typo in original: x_axis_y should be y_axis_x for y component\n",
    "        rotated_scaled_y = (x_axis_y * old_x) + (\n",
    "            y_axis_y * old_y\n",
    "        )  # Typo in original: y_axis_x should be x_axis_y for x component\n",
    "        # Corrected:\n",
    "        rotated_scaled_x = (cos_rot * old_x - sin_rot * old_y) * scale\n",
    "        rotated_scaled_y = (sin_rot * old_x + cos_rot * old_y) * scale\n",
    "\n",
    "        new_x = rotated_scaled_x + move_x\n",
    "        new_y = rotated_scaled_y + move_y\n",
    "        new_points.append({\"x\": new_x, \"y\": new_y})\n",
    "    return new_points\n",
    "\n",
    "\n",
    "def save_strokes_as_images(\n",
    "    strokes_list, root_folder, width, height, augment_count_per_image\n",
    "):\n",
    "    ensure_empty_dir(root_folder)\n",
    "    for label_str in LABELS:\n",
    "        label_path = Path(root_folder, label_str)\n",
    "        ensure_empty_dir(label_path)\n",
    "\n",
    "    label_counts = {label_str: 0 for label_str in LABELS}\n",
    "\n",
    "    for stroke in strokes_list:\n",
    "        points = stroke[\"strokePoints\"]\n",
    "        label = str(stroke[\"label\"]).strip().lower()\n",
    "        current_label_count = label_counts[label]\n",
    "        label_counts[label] += 1\n",
    "\n",
    "        # Save original rasterized image\n",
    "        raster = rasterize_stroke(points, X_RANGE, Y_RANGE, width, height)\n",
    "        image = PIL.Image.fromarray(raster)\n",
    "        image.save(Path(root_folder, label, f\"{current_label_count}.png\"))\n",
    "\n",
    "        # Save augmented versions\n",
    "        for i in range(augment_count_per_image):\n",
    "            augmented_points = augment_points(\n",
    "                points, move_range=0.0, scale_range=0.1, rotate_range=0.3\n",
    "            )\n",
    "            raster_aug = rasterize_stroke(\n",
    "                augmented_points, X_RANGE, Y_RANGE, width, height\n",
    "            )\n",
    "            image_aug = PIL.Image.fromarray(raster_aug)\n",
    "            image_aug.save(Path(root_folder, label, f\"{current_label_count}_a{i}.png\"))\n",
    "\n",
    "    print(f\"Saved images to {root_folder}. Label counts: {label_counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b30159",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_strokes = list(strokes)\n",
    "np.random.shuffle(shuffled_strokes)\n",
    "\n",
    "# Define dataset split percentages\n",
    "test_percentage = 20\n",
    "validation_percentage = 20\n",
    "train_percentage = 100 - (test_percentage + validation_percentage)\n",
    "\n",
    "# Calculate counts\n",
    "total_filtered_strokes = len(shuffled_strokes)\n",
    "test_count = math.floor((total_filtered_strokes * test_percentage) / 100)\n",
    "validation_count = math.floor((total_filtered_strokes * validation_percentage) / 100)\n",
    "\n",
    "# Split\n",
    "test_strokes = shuffled_strokes[0:test_count]\n",
    "validation_strokes = shuffled_strokes[test_count : (test_count + validation_count)]\n",
    "train_strokes = shuffled_strokes[(test_count + validation_count) :]\n",
    "\n",
    "print(f\"Total strokes for processing: {total_filtered_strokes}\")\n",
    "print(f\"Training strokes: {len(train_strokes)}\")\n",
    "print(f\"Validation strokes: {len(validation_strokes)}\")\n",
    "print(f\"Test strokes: {len(test_strokes)}\")\n",
    "\n",
    "AUGMENT_TRAIN = 10\n",
    "AUGMENT_VAL = 0\n",
    "AUGMENT_TEST = 0\n",
    "\n",
    "# Create the image datasets\n",
    "if train_strokes:\n",
    "    save_strokes_as_images(\n",
    "        train_strokes, \"train\", IMAGE_WIDTH, IMAGE_HEIGHT, AUGMENT_TRAIN\n",
    "    )\n",
    "else:\n",
    "    print(\"No training strokes to save.\")\n",
    "    Path(\"train\").mkdir(exist_ok=True)\n",
    "\n",
    "if validation_strokes:\n",
    "    save_strokes_as_images(\n",
    "        validation_strokes, \"validation\", IMAGE_WIDTH, IMAGE_HEIGHT, AUGMENT_VAL\n",
    "    )\n",
    "else:\n",
    "    print(\"No validation strokes to save.\")\n",
    "    Path(\"validation\").mkdir(exist_ok=True)\n",
    "\n",
    "if test_strokes:\n",
    "    save_strokes_as_images(\n",
    "        test_strokes, \"test\", IMAGE_WIDTH, IMAGE_HEIGHT, AUGMENT_TEST\n",
    "    )\n",
    "else:\n",
    "    print(\"No test strokes to save.\")\n",
    "    Path(\"test\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b62d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "for label in LABELS:\n",
    "    Path(f\"train/{label}\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"validation/{label}\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"test/{label}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "loaded_class_names = None\n",
    "\n",
    "try:\n",
    "    train_ds_temp = image_dataset_from_directory(\n",
    "        directory=\"train\",\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "        shuffle=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    loaded_class_names = train_ds_temp.class_names\n",
    "    train_ds = train_ds_temp.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    del train_ds_temp\n",
    "\n",
    "    validation_ds_temp = image_dataset_from_directory(\n",
    "        directory=\"validation\",\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "        shuffle=False,\n",
    "    )\n",
    "    validation_ds = validation_ds_temp.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    del validation_ds_temp\n",
    "\n",
    "    test_ds_temp = image_dataset_from_directory(\n",
    "        directory=\"test\",\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "        shuffle=False,\n",
    "    )\n",
    "    test_ds = test_ds_temp.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    del test_ds_temp\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in train_ds.take(1):\n",
    "        for i in range(min(9, images.shape[0])):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "            label_index = np.argmax(labels[i])\n",
    "            plt.title(f\"Label: {loaded_class_names[label_index]}\")\n",
    "            plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading datasets: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528429f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def make_model(input_shape, _num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(16, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Classifier block\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    activation = \"softmax\"\n",
    "    units = _num_classes\n",
    "\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model_input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS)\n",
    "model = make_model(input_shape=model_input_shape, _num_classes=NUM_CLASSES)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "display(keras.utils.plot_model(model, show_shapes=True, expand_nested=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b079f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# ModelCheckpoint to save the best model during training\n",
    "checkpoint_filepath = \"checkpoints/best_model.keras\"\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "# EarlyStopping to prevent overfitting\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "callbacks_list = [model_checkpoint_callback, early_stopping_callback]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "print(f\"Starting training for {EPOCHS} epochs...\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_data=validation_ds,\n",
    ")\n",
    "\n",
    "if history and history.history:\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
    "    plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
    "    plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.show()\n",
    "\n",
    "model = keras.models.load_model(checkpoint_filepath)\n",
    "\n",
    "print(\"Evaluating model on the test dataset...\")\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f57ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_keras(keras_model, image_path, class_names_list_param):\n",
    "    img = keras.preprocessing.image.load_img(\n",
    "        image_path, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "    )\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = keras_model.predict(img_array, verbose=0).flatten()\n",
    "    predicted_label_index = np.argmax(predictions)\n",
    "    predicted_score = predictions[predicted_label_index]\n",
    "\n",
    "    if class_names_list_param and 0 <= predicted_label_index < len(\n",
    "        class_names_list_param\n",
    "    ):\n",
    "        predicted_label_name = class_names_list_param[predicted_label_index]\n",
    "    else:\n",
    "        predicted_label_name = f\"Unknown (Index {predicted_label_index})\"\n",
    "    return (predicted_label_name, predicted_label_index, predicted_score)\n",
    "\n",
    "\n",
    "SCORE_THRESHOLD = 0.75\n",
    "correct_count = 0\n",
    "wrong_count = 0\n",
    "discarded_count = 0\n",
    "\n",
    "print(f\"\\nDetailed predictions on test images (threshold: {SCORE_THRESHOLD}):\")\n",
    "for label_str in loaded_class_names:\n",
    "    label_dir = Path(\"test\") / label_str\n",
    "    for image_file in glob.glob(str(label_dir / \"*.png\")):\n",
    "        true_label_name = label_str\n",
    "\n",
    "        pred_label_name, pred_label_idx, score = predict_image_keras(\n",
    "            model, image_file, loaded_class_names\n",
    "        )\n",
    "\n",
    "        if score < SCORE_THRESHOLD:\n",
    "            discarded_count += 1\n",
    "            continue\n",
    "\n",
    "        if pred_label_name == true_label_name:\n",
    "            correct_count += 1\n",
    "        else:\n",
    "            wrong_count += 1\n",
    "            print(\n",
    "                f\"File: {Path(image_file).name} - Expected: {true_label_name}, \"\n",
    "                f\"Predicted: {pred_label_name} with score {score:.4f}\"\n",
    "            )\n",
    "\n",
    "if (correct_count + wrong_count) > 0:\n",
    "    detailed_accuracy = (correct_count / (correct_count + wrong_count)) * 100\n",
    "    print(\n",
    "        f\"\\nDetailed Test Accuracy (above threshold): {detailed_accuracy:.1f}% \"\n",
    "        f\"(Correct: {correct_count}, Wrong: {wrong_count}, Discarded: {discarded_count})\"\n",
    "    )\n",
    "\n",
    "model.export(SAVED_MODEL_FILENAME)\n",
    "print(f\"Model saved to {SAVED_MODEL_FILENAME} folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76746cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nConverting to Float TFLite model from: {SAVED_MODEL_FILENAME}\")\n",
    "converter_float = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_FILENAME)\n",
    "model_float_tflite = converter_float.convert()\n",
    "\n",
    "with open(FLOAT_TFL_MODEL_FILENAME, \"wb\") as f:\n",
    "    f.write(model_float_tflite)\n",
    "print(f\"Float TFLite model saved to: {FLOAT_TFL_MODEL_FILENAME}\")\n",
    "\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    num_calibration_steps = 100\n",
    "    calibration_ds = train_ds.unbatch().take(num_calibration_steps).batch(1)\n",
    "\n",
    "    for image_batch, _ in calibration_ds:\n",
    "        yield [image_batch]\n",
    "\n",
    "\n",
    "print(f\"\\nConverting to Quantized INT8 TFLite model from: {SAVED_MODEL_FILENAME}\")\n",
    "converter_quant = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_FILENAME)\n",
    "converter_quant.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter_quant.representative_dataset = representative_dataset_gen\n",
    "converter_quant.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter_quant.inference_input_type = tf.int8\n",
    "converter_quant.inference_output_type = tf.int8\n",
    "model_quantized_tflite = converter_quant.convert()\n",
    "\n",
    "with open(QUANTIZED_TFL_MODEL_FILENAME, \"wb\") as f:\n",
    "    f.write(model_quantized_tflite)\n",
    "print(f\"Quantized INT8 TFLite model saved to: {QUANTIZED_TFL_MODEL_FILENAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tflite(tflite_model_content, image_path, class_names_list_param):\n",
    "    \"\"\"\n",
    "    Performs inference using a TFLite model and returns predicted label and score.\n",
    "    \"\"\"\n",
    "    img = keras.preprocessing.image.load_img(\n",
    "        image_path, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "    )\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0).astype(np.float32)\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model_content)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "    if input_details[\"dtype\"] == np.int8:\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "\n",
    "        if (input_scale, input_zero_point) != (0.0, 0):\n",
    "            img_array = (img_array / input_scale) + input_zero_point\n",
    "        img_array = img_array.astype(input_details[\"dtype\"])\n",
    "\n",
    "    interpreter.set_tensor(input_details[\"index\"], img_array)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output_data = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    if output_details[\"dtype\"] == np.int8:\n",
    "        output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "        if (output_scale, output_zero_point) != (0.0, 0):\n",
    "            output_data = output_data.astype(np.float32)\n",
    "            output_data = (output_data - output_zero_point) * output_scale\n",
    "\n",
    "    predicted_label_index = np.argmax(output_data)\n",
    "    predicted_score = output_data[predicted_label_index]\n",
    "    if class_names_list_param and 0 <= predicted_label_index < len(\n",
    "        class_names_list_param\n",
    "    ):\n",
    "        predicted_label_name = class_names_list_param[predicted_label_index]\n",
    "\n",
    "    return (predicted_label_name, predicted_label_index, predicted_score)\n",
    "\n",
    "\n",
    "def evaluate_tflite_model(\n",
    "    model_content, model_name, class_names_eval, score_threshold_eval\n",
    "):\n",
    "    print(\n",
    "        f\"\\nEvaluating {model_name} on test images (threshold: {score_threshold_eval}):\"\n",
    "    )\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    discarded = 0\n",
    "\n",
    "    for label_str in class_names_eval:\n",
    "        label_dir = Path(\"test\") / label_str\n",
    "        for image_file in glob.glob(str(label_dir / \"*.png\")):\n",
    "            true_label_name = label_str\n",
    "\n",
    "            pred_label_name, _, score = predict_tflite(\n",
    "                model_content, image_file, class_names_eval\n",
    "            )\n",
    "\n",
    "            if score < score_threshold_eval:\n",
    "                discarded += 1\n",
    "                continue\n",
    "\n",
    "            if pred_label_name == true_label_name:\n",
    "                correct += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "\n",
    "    accuracy = 0\n",
    "\n",
    "    if (correct + wrong) > 0:\n",
    "        accuracy = (correct / (correct + wrong)) * 100\n",
    "        print(\n",
    "            f\"{model_name} - Accuracy (above threshold): {accuracy:.1f}% \"\n",
    "            f\"(Correct: {correct}, Wrong: {wrong}, Discarded: {discarded})\"\n",
    "        )\n",
    "    return accuracy, correct, wrong, discarded\n",
    "\n",
    "\n",
    "if Path(FLOAT_TFL_MODEL_FILENAME).exists():\n",
    "    with open(FLOAT_TFL_MODEL_FILENAME, \"rb\") as f:\n",
    "        model_float_tflite_content = f.read()\n",
    "    evaluate_tflite_model(\n",
    "        model_float_tflite_content,\n",
    "        \"Float TFLite Model\",\n",
    "        loaded_class_names,\n",
    "        SCORE_THRESHOLD,\n",
    "    )\n",
    "\n",
    "if Path(QUANTIZED_TFL_MODEL_FILENAME).exists():\n",
    "    evaluate_tflite_model(\n",
    "        model_quantized_tflite,\n",
    "        \"Quantized INT8 TFLite Model\",\n",
    "        loaded_class_names,\n",
    "        SCORE_THRESHOLD,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91f24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if Path(QUANTIZED_TFL_MODEL_FILENAME).exists():\n",
    "    print(\n",
    "        f\"\\nConverting {QUANTIZED_TFL_MODEL_FILENAME} to C source file: {TFL_CC_MODEL_FILENAME}\"\n",
    "    )\n",
    "    xxd_command = f\"xxd -i {QUANTIZED_TFL_MODEL_FILENAME} > {TFL_CC_MODEL_FILENAME}\"\n",
    "    if os.system(xxd_command) == 0:\n",
    "        print(f\"Successfully created C source file: {TFL_CC_MODEL_FILENAME}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
